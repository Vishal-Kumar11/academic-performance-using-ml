# Architecture Documentation

## Academic Performance Prediction using Machine Learning

### System Architecture Overview

This document describes the technical architecture and design decisions for the Academic Performance Prediction system.

---

## ğŸ—ï¸ System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   ML Pipeline   â”‚
â”‚   (Bootstrap 5) â”‚â—„â”€â”€â–ºâ”‚   (Flask)       â”‚â—„â”€â”€â–ºâ”‚   (13 Models)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Static Files  â”‚    â”‚   API Routes    â”‚    â”‚   Data Storage  â”‚
â”‚   (CSS/JS)      â”‚    â”‚   (REST)        â”‚    â”‚   (Artifacts)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Architecture

#### 1. Frontend Layer
- **Technology:** Bootstrap 5, JavaScript, HTML5/CSS3
- **Components:** Templates, Static assets, Interactive visualizations
- **Features:** Responsive design, Real-time validation, AJAX requests

#### 2. Backend Layer
- **Technology:** Flask 3.0, Python 3.8+
- **Components:** Routes, API endpoints, Error handling
- **Features:** RESTful API, Input validation, Logging

#### 3. ML Pipeline Layer
- **Technology:** scikit-learn, XGBoost, TensorFlow
- **Components:** Data processing, Model training, Prediction
- **Features:** 13 ML models, Cross-validation, Hyperparameter tuning

---

## ğŸ”„ Data Flow Architecture

### Training Pipeline Flow

```
Raw Data â†’ Data Ingestion â†’ Data Transformation â†’ Model Training â†’ Model Evaluation â†’ Model Persistence
    â”‚            â”‚                    â”‚                    â”‚                    â”‚                    â”‚
    â–¼            â–¼                    â–¼                    â–¼                    â–¼                    â–¼
CSV Files â†’ Train/Test Split â†’ Feature Engineering â†’ 13 ML Models â†’ Performance Metrics â†’ PKL/H5 Files
```

### Prediction Pipeline Flow

```
User Input â†’ Input Validation â†’ Data Preprocessing â†’ Model Loading â†’ Prediction â†’ Result Formatting â†’ Response
    â”‚              â”‚                    â”‚                    â”‚              â”‚                    â”‚              â”‚
    â–¼              â–¼                    â–¼                    â–¼              â–¼                    â–¼              â–¼
Web Form â†’ Type Checking â†’ Feature Scaling â†’ Load Model â†’ ML Prediction â†’ Confidence Score â†’ JSON/HTML
```

---

## ğŸ§  Machine Learning Architecture

### Model Training Architecture

```python
# Training Pipeline
class AcademicModelTrainer:
    def __init__(self):
        self.models = {
            'XGBoost': XGBRegressor(),
            'LightGBM': LGBMRegressor(),
            'CatBoost': CatBoostRegressor(),
            'Neural Network': Sequential(),
            # ... 9 more models
        }
    
    def train_models(self):
        for name, model in self.models.items():
            # Hyperparameter tuning
            best_model = GridSearchCV(model, params, cv=5)
            # Cross-validation
            cv_scores = cross_val_score(best_model, X, y, cv=5)
            # Model evaluation
            metrics = self.evaluate_model(best_model)
```

### Model Selection Strategy

1. **Hyperparameter Tuning:** GridSearchCV with 5-fold CV
2. **Cross-Validation:** 5-fold stratified cross-validation
3. **Evaluation Metrics:** RÂ², MAE, RMSE, MAPE, Explained Variance
4. **Model Selection:** Best RÂ² score with lowest variance
5. **Model Persistence:** PKL for sklearn, H5 for TensorFlow

---

## ğŸ¨ Frontend Architecture

### Template Structure

```
base.html (Base Template)
â”œâ”€â”€ Navigation Bar
â”œâ”€â”€ Main Content Block
â”œâ”€â”€ Footer
â””â”€â”€ Scripts

home.html (Landing Page)
â”œâ”€â”€ Hero Section
â”œâ”€â”€ Features Section
â”œâ”€â”€ Statistics Section
â””â”€â”€ Call-to-Action

predict.html (Prediction Form)
â”œâ”€â”€ Form Validation
â”œâ”€â”€ Input Fields
â”œâ”€â”€ Help Cards
â””â”€â”€ Submit Button

results.html (Results Display)
â”œâ”€â”€ Prediction Display
â”œâ”€â”€ Input Summary
â”œâ”€â”€ Feature Importance Chart
â””â”€â”€ Action Buttons
```

### JavaScript Architecture

```javascript
// Main Application Controller
class AcademicMLApp {
    constructor() {
        this.initializeComponents();
        this.setupEventListeners();
        this.initializeCharts();
    }
    
    // Form validation and submission
    handleFormSubmission() {
        // Real-time validation
        // AJAX requests
        // Error handling
    }
    
    // Chart initialization
    initializeCharts() {
        // Plotly integration
        // Interactive visualizations
    }
}
```

---

## ğŸ”§ Backend Architecture

### Flask Application Structure

```python
# Application Factory Pattern
def create_app():
    app = Flask(__name__)
    
    # Configuration
    app.config.from_object(Config)
    
    # Blueprint registration
    app.register_blueprint(main_bp)
    app.register_blueprint(api_bp)
    
    # Error handlers
    app.register_error_handler(404, not_found_error)
    app.register_error_handler(500, internal_error)
    
    return app
```

### Route Architecture

```python
# Main Routes
@app.route('/')                    # Home page
@app.route('/predict')            # Single prediction
@app.route('/batch')              # Batch processing
@app.route('/dashboard')          # Model dashboard
@app.route('/about')              # About page

# API Routes
@app.route('/api/predict')        # Prediction API
@app.route('/api/model-info')     # Model information API
```

---

## ğŸ“Š Data Architecture

### Data Processing Pipeline

```python
# Data Ingestion
class AcademicDataIngestion:
    def initiate_data_ingestion(self):
        # Load raw data
        # Train-test split
        # Save processed data
        
# Data Transformation
class AcademicDataTransformation:
    def get_data_transformer_object(self):
        # Numerical pipeline
        # Categorical pipeline
        # Column transformer
        
# Model Training
class AcademicModelTrainer:
    def initiate_model_trainer(self):
        # Load processed data
        # Train 13 models
        # Evaluate performance
        # Save best model
```

### Feature Engineering

```python
# Numerical Features
numerical_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Categorical Features
categorical_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('one_hot_encoder', OneHotEncoder()),
    ('scaler', StandardScaler(with_mean=False))
])
```

---

## ğŸ”’ Security Architecture

### Input Validation

```python
class AcademicDataValidator:
    def validate_prediction_input(self, input_data):
        # Type checking
        # Range validation
        # Format validation
        # Security checks
```

### Error Handling

```python
# Custom Exception Handling
class CustomException(Exception):
    def __init__(self, error_message, error_detail):
        super().__init__(error_message)
        self.error_message = error_message
        self.error_detail = error_detail

# Global Error Handlers
@app.errorhandler(404)
def not_found_error(error):
    return render_template('home.html'), 404
```

---

## ğŸ“ˆ Performance Architecture

### Caching Strategy

```python
# Model Caching
@lru_cache(maxsize=1)
def load_model():
    return joblib.load('artifacts/academic_performance_model.pkl')

# Preprocessing Caching
@lru_cache(maxsize=1)
def load_preprocessor():
    return joblib.load('artifacts/academic_preprocessor.pkl')
```

### Optimization Techniques

1. **Model Persistence:** Pre-trained models loaded once
2. **Batch Processing:** Efficient CSV processing
3. **Lazy Loading:** Components loaded on demand
4. **Memory Management:** Proper cleanup and garbage collection

---

## ğŸš€ Deployment Architecture

### Production Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Load Balancer â”‚    â”‚   Web Server     â”‚    â”‚   Application   â”‚
â”‚   (AWS ALB)     â”‚â—„â”€â”€â–ºâ”‚   (Nginx)        â”‚â—„â”€â”€â–ºâ”‚   (Flask)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CDN           â”‚    â”‚   Static Files  â”‚    â”‚   ML Models     â”‚
â”‚   (CloudFront)  â”‚    â”‚   (S3)          â”‚    â”‚   (S3)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Container Architecture

```dockerfile
# Multi-stage Docker build
FROM python:3.8-slim as base
# Install system dependencies
# Install Python packages
# Copy application code
# Expose port 5000
```

---

## ğŸ” Monitoring Architecture

### Logging Strategy

```python
# Structured Logging
import logging

# Application logs
app_logger = logging.getLogger('academic_ml')

# Model logs
model_logger = logging.getLogger('academic_ml.model')

# API logs
api_logger = logging.getLogger('academic_ml.api')
```

### Metrics Collection

1. **Performance Metrics:** Response time, throughput
2. **Model Metrics:** Prediction accuracy, confidence scores
3. **System Metrics:** CPU, memory, disk usage
4. **User Metrics:** Page views, prediction requests

---

## ğŸ”„ CI/CD Architecture

### Continuous Integration

```yaml
# GitHub Actions Workflow
name: CI/CD Pipeline
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - Checkout code
      - Setup Python
      - Install dependencies
      - Run tests
      - Code quality checks
```

### Deployment Pipeline

1. **Code Commit** â†’ GitHub
2. **Automated Testing** â†’ pytest, flake8
3. **Build Docker Image** â†’ Docker Hub
4. **Deploy to AWS** â†’ Elastic Beanstalk
5. **Health Checks** â†’ Application monitoring

---

## ğŸ“š API Architecture

### RESTful API Design

```python
# API Endpoints
GET  /api/model-info          # Model information
POST /api/predict             # Single prediction
POST /api/batch-predict       # Batch prediction
GET  /api/health              # Health check
```

### API Response Format

```json
{
  "success": true,
  "prediction": 85.7,
  "confidence": "high",
  "model_used": "XGBoost",
  "processing_time": 0.023,
  "timestamp": "2024-01-15T10:30:00Z"
}
```

---

## ğŸ¯ Future Architecture Considerations

### Scalability Improvements

1. **Microservices:** Split into separate services
2. **Message Queues:** Async processing for batch jobs
3. **Database:** Persistent storage for predictions
4. **Caching:** Redis for model caching
5. **Load Balancing:** Multiple application instances

### Technology Upgrades

1. **FastAPI:** Replace Flask for better performance
2. **MLflow:** Model versioning and tracking
3. **Kubernetes:** Container orchestration
4. **GraphQL:** More flexible API queries
5. **WebSockets:** Real-time updates

---

This architecture document provides a comprehensive overview of the system design, helping developers understand the codebase structure and make informed decisions about future enhancements.
